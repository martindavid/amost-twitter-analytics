{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import couchdb\n",
    "from lib.genderComputer.genderComputer import GenderComputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = couchdb.Server(url='http://127.0.0.1:15984/')\n",
    "db = server['tweets']\n",
    "gc = GenderComputer(os.path.abspath('./data/nameLists'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'2017/3/10', u'2017/3/11', u'2017/3/12', u'2017/3/13', u'2017/3/14', u'2017/3/15', u'2017/3/16', u'2017/3/17', u'2017/3/18', u'2017/3/19', u'2017/3/20', u'2017/3/21', u'2017/3/22', u'2017/3/23', u'2017/3/24', u'2017/3/25', u'2017/3/26', u'2017/3/27', u'2017/3/28', u'2017/3/29', u'2017/3/30', u'2017/3/6', u'2017/3/7', u'2017/3/8', u'2017/3/9', u'2017/4/1', u'2017/4/2', u'2017/4/3', u'2017/4/4', u'2017/4/5', u'2017/4/6', u'2017/4/7', u'2017/4/8']\n"
     ]
    }
   ],
   "source": [
    "date_list = []\n",
    "for row in db.view('_design/analytics/_view/conversation-date-breakdown', reduce=True, group=True):\n",
    "    date_list.append(row.key)\n",
    "    \n",
    "print(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "view_data = []\n",
    "for row in db.view('_design/analytics/_view/tweets-victoria',startkey=\"2017/3/6\",endkey=\"2017/3/9\"):\n",
    "    view_data.append(row.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(view_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    hashtags = server.create[\"twitter-hashtags\"]\n",
    "except:\n",
    "    hashtags = server[\"twitter-hashtags\"]\n",
    "\n",
    "hashtag_count = Counter()\n",
    "\n",
    "for row in view_data:\n",
    "    hashtag_count.update(row[\"hashtags\"])\n",
    "\n",
    "for tag in hashtag_count.most_common():\n",
    "    doc = hashtags.get(tag[0]) # tag[0] -> hashtag, tag[1] -> frequency\n",
    "    if doc is None:\n",
    "        data = {}\n",
    "        data[\"_id\"] = tag[0].replace('\\u','') # use word as an id\n",
    "        data[\"hashtag\"] = tag[0].replace('\\u','')\n",
    "        data[\"count\"] = tag[1]\n",
    "    else:\n",
    "        data = doc\n",
    "        data[\"count\"] = data[\"count\"] + tag[1]\n",
    "    \n",
    "    hashtags.save(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "users = []\n",
    "for row in view_data:\n",
    "    text = {}\n",
    "    text[\"text\"] = row[\"text\"]\n",
    "    text[\"sentiment\"] = row[\"sentiment\"]\n",
    "    texts.append(text)\n",
    "    user = row[\"user\"]\n",
    "    try:\n",
    "        gender = gc.resolveGender(user[\"name\"], None)\n",
    "        user[\"gender\"] = gender\n",
    "    except:\n",
    "        continue\n",
    "    users.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('text', 254, ' user', 254)\n"
     ]
    }
   ],
   "source": [
    "print(\"text\",len(texts),\" user\", len(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    " \n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save Terms Frequency\n",
    "import HTMLParser\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "punctuation = list(string.punctuation)\n",
    "stop = stopwords.words('english') + punctuation + ['rt', 'via']\n",
    "count_all = Counter()\n",
    "html_parser = HTMLParser.HTMLParser()\n",
    "emoji_pattern = re.compile(\n",
    "    u\"(\\ud83d[\\ude00-\\ude4f])|\"  # emoticons\n",
    "    u\"(\\ud83c[\\udf00-\\uffff])|\"  # symbols & pictographs (1 of 2)\n",
    "    u\"(\\ud83d[\\u0000-\\uddff])|\"  # symbols & pictographs (2 of 2)\n",
    "    u\"(\\ud83d[\\ude80-\\udeff])|\"  # transport & map symbols\n",
    "    u\"(\\ud83c[\\udde0-\\uddff])\"  # flags (iOS)\n",
    "    \"+\", flags=re.UNICODE)\n",
    "for text in texts:\n",
    "    cleanText = re.sub(r\"http\\S+\", \"\", text['text'])\n",
    "    cleanText = html_parser.unescape(cleanText)\n",
    "    cleanText = emoji_pattern.sub(r'', cleanText)\n",
    "    terms_stop = [term for term in preprocess(cleanText) if term not in stop]\n",
    "    count_all.update(terms_stop)\n",
    "\n",
    "try:\n",
    "    words = server.create[\"twitter-words\"]\n",
    "except:\n",
    "    words = server[\"twitter-words\"]\n",
    "    \n",
    "for num in count_all.most_common():\n",
    "    doc = words.get(num[0]) # num[0] -> word, num[1] -> frequency\n",
    "    try:\n",
    "        if doc is None:\n",
    "            data = {}\n",
    "            word_text = num[0].decode(\"utf8\").encode('ascii','ignore') # make sure we don't save unsafe character\n",
    "            data[\"_id\"] = word_text # use word as an id\n",
    "            data[\"word\"] = word_text\n",
    "            data[\"count\"] = num[1]\n",
    "        else:\n",
    "            data = doc\n",
    "            data[\"count\"] = data[\"count\"] + num[1]\n",
    "        words.save(data)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save user data\n",
    "# try create user db\n",
    "try:\n",
    "    user = server.create[\"twitter-users\"]\n",
    "except:\n",
    "    user = server[\"twitter-users\"]\n",
    "    \n",
    "for row in users:\n",
    "    id = row[\"id\"]\n",
    "    doc = user.get(str(id))\n",
    "    if doc is None:\n",
    "        row[\"_id\"] = str(row[\"id\"])\n",
    "        user.save(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"â˜•\".decode(\"utf8\").encode('ascii','ignore') == \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/5/9\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "today = datetime.date.today()\n",
    "today = today.strftime('%Y/%-m/%-d')\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
